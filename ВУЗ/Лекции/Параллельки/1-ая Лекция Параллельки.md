>[!info] Параллелизм 
>могут быть выполнены независимо и одновременно

>[!info] Конкурентность
>одновременный доступ к ресурсу

>[!info] Асинхронность
>не дожидается завершения задачи; обработает результат, когда завершится задача


## 1. Параллелизм
Уровни параллелизма:
1. Битов
2. Инструкций
	1. Конвейер
	2. Супер скалярность (дублирование блоков в процессоре)
3. Данных (SIMD - инструкции)
4. Задач

## 2. Таксономия Флинна
I - инструкции 
D - данные

S - один
M - много

| Type | S    | M    |
| ---- | ---- | ---- |
| S    | SISD | SIMD |
| M    | MISD | MIMD |

### SIMD:
x86: MMX; SSE; AVX
arm: NEON
risc-v: V, P

### MISD:
- хуйня

### MIMD:
- Многоядерные процессоры, где ядро может работать с несколькими данными

### SIMT:
T - thread
Между SIMD и MIMD
- Для видеокарт 
- Есть один поток инструкций  (на специальную группу потоков). Похож на SIMD. Потоков одновременно может быть несколько.

## 3. Закон Амдала
> Оценка на эффективность распараллели

- Фиксированный объем задачи.

> [!info] Объем задачи
> количество инструкций нужно выполнить для решения задачи

- N - число процессоров
- s - доля последовательных вычислений (не можем распараллелить)
- p - доля параллелизуемых вычислений
- s + p = 1
- T<sub>i</sub> -  времня на i процессорах
- $$S =\frac{T_i}{T_N} = \frac{T_1(s+p)}{S*T_1+p*\frac{T_1}{N}} = \frac{1}{S+\frac{p}{N}}=\frac{1}{S+\frac{1-s}{N}} \rightarrow \frac{1}{S}$$ 
Максимум в 20 раз прирост. Есть порог после которого эффективность параллелизма значительно падает.

## 4. Закон Густафсона (-Барсиса)  
- Время фиксировано

- N - число процессоров
- s - доля последовательных вычислений (не можем распараллелить)
- p - доля параллелизуемых вычислений
- s + p = 1
- T<sub>i</sub> -  времня на i процессорах
- V<sub>i</sub> - объем задачи на i процессорах

$$S = \frac{V_N}{V_1} = \frac{V_1S +V_1 \space p*n}{V_1}= s + (1-s)n = n+s - ns = n + (1-n)s$$

## 5. Содержательные задачи

0. Файберы                       |   
1. Многопоточность        | Акселераторы GPGPU, FPGA, ASIC
2. Многопроцессность   |
3. Кластер (много компьютеров)
------------------
Вне курса
4. Децентрализованные вычисления
	- Блокчейн


## 6. Многопроцессность

IPC:
- socket
- shared memory
- pipes
- rpc
- семафоры
- сигналы
- файлы
- message queue
---

- smp (symmetric multiprocessor) - ядра имеют одинаковый(равноценный) доступ к памяти

- numa (non uniform memory access) - ядра имеют не равномерный доступ к памяти, могут запрашивать друг у друга доступ, но желательно работать со своей локальной памяти (у ядра своя память)

- asmp (asymmetric multiprocessor) - ядра не равнозначны

- multithreading - ядро жует свой поток инструию, остоновка конвейера нет чего-либо в кеше. На одну группу вычислительных узлов заводим 2 потока

## 7. Классическая задача (обедающие философы)

> Есть круглый стол за которым по кругу сидят философы. Между ними лежит по вилке и перед ними тарелки. Каждый философ сидит думает, чтобы поесть ему нужно взять 2 вилки, когда он держит вилку никто отобрать не может. Если возьмет 2 вилки может поесть. 
> Придумать такой алгоритм действия для каждого философа, чтобы они могли поесть, подумать, поесть когда захотят.

Идея пронумеровать вилки (упорядочить) и брать меньшую (тем самым не будут блокировать друг друга). Не появляется петля

## 8. Литерарута
- Is Parallel Programming Hard, And, If so, What can you do about it. - Open source
- [The Art of Multiprocessor Programming](obsidian://open?vault=zametki&file=%D0%92%D0%A3%D0%97%2F%D0%9B%D0%B8%D1%82%D0%B5%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%2FThe_Art_of_Multiprocessor_Programming_2nd_edition_2021_Herlihy_Shavit.pdf) - M. Herlihy, Nir Shavit
- [Параллельное программирование](obsidian://open?vault=zametki&file=%D0%92%D0%A3%D0%97%2F%D0%9B%D0%B8%D1%82%D0%B5%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%2Fteoriya_i_praktika_parallel_nykh_vychisleniy.pdf) - Гергель

## 9. Домашки
хуй знают как они будут. Если как в прошлом году, заставят следовать дедлайнам. Будут строгие дедлайны. Не будет тонны домашек, но может чуть хитрее